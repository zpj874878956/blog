---
title: elk安装
categories: 
  - elk
tags: 
  - elk
date: 2022-12-09 20:50:18
permalink: /pages/98c9f5/
---

## ELK服务部署

### 官网下载对应版本的二进制压缩包

elasticsearch 官网下载地址：
https://www.elastic.co/cn/downloads/elasticsearch
elasticsearch 历史版本下载地址：
 https://www.elastic.co/cn/downloads/past-releases#elasticsearch

kinbana 官网下载地址：
https://www.elastic.co/cn/downloads/kibana
kinbana 历史版本下载地址：
https://www.elastic.co/cn/downloads/past-releases#kibana

logstash 官网下载地址：
https://www.elastic.co/cn/downloads/logstash
logstash 历史版本下载地址：
https://www.elastic.co/cn/downloads/past-releases

---

### 解压、准备工作、启动ELK

elasticsearch.tar.gz文件解压

tar -zxvf 就可以啦
太基础的废话命令就不罗列啦，主要是提几个关键的细节的点
比如elasticsearch部署的时候需要注意：

1. 使用普通用户
2. 开启max_map_count
3. 设置对应普通用户limit.conf
4. useradd -d /data/es es &&echo es | passwd --stdin es
5. echo "vm.max_map_count=655360" >> /etc/sysctl.conf
6. echo "es soft nofile 655350" >> /etc/security/limits.conf && echo "es hard nofile 655350" >> /etc/security/limits.conf
   sysctl -p 刷新一下另其生效

然后准备个对应的jdk配置个全局的环境变量：

> JAVA_HOME=/opt/jdk1.8.0_65
> PATH=$JAVA_HOME/bin:$PATH
> CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
> 追加至系统环境变量文件尾部即可或者普通用户的
> /etc/profile
> .bash_profile
> .bashrc
> 然后给刷新一下环境变量或者exit退出用户重新登录即可刷新
> 登录普通用户记得带上杠表示带着普通用户的环境变量呢 su - es
> source /etc/profile
> 当我使用elasticsearch-no-jdk-7.9.6.tar.gz版本包时,启动提示要找本地普通用户家目录下面的java
> 例如上面的es用户 elastic为解压包
> /data/es/elastic/jdk/bin/java
> 配置了全局的环境变量 指定目录的opt jdk java都不行还要去找上面目录的java
> 此时我们可以懒得理他直接根据启动log错误信息解决即可啦
> 使用“小大招”直接软连接射过去就好啦
> 当然前提对应的elastic解压包目录要创建对应的log提示的路劲目录 不然软连接找不到上一层目录无法创建哒
> mkdir -p /data/es/elastic/jdk/bin/
> ln -sf /opt/jdk/java/bin/java /data/es/elastic/jdk/bin/

然后配置改吧改吧修改修改elasticsearch.yml文件

> cat elasticsearch/config/elasticsearch.yml
> cluster.name: pengge
> #bootstrap.mlockall: true
> thread_pool.search.size: 10
> thread_pool.search.queue_size: 3000
> thread_pool.bulk.size: 5
> thread_pool.bulk.queue_size: 2000
> thread_pool.index.size: 5
> thread_pool.index.queue_size: 1500
> node.name: node-pengge
> cluster.initial_master_nodes: ["node-pengge"]
> path.data: /data/es/elastic/data
> path.logs: /data/elastic/logs
> network.host: 192.168.108.8
> http.port: 9200
> transport.tcp.port: 9300
> transport.tcp.compress: false
> discovery.zen.ping.unicast.hosts: ["192.168.108.8", "192.168.108.9", "192.168.108.10"]

然后就可以启动es节点啦，上面实例yml配置文件是配置的三节点集群，多节点集群也是一样的道理逗号添加集群节点ip即可啦，简简单单部署那是十分的轻松啦
 ./elasticsearch &> esstart.log & && tail -f esstart.log
直接sh或者./启动二进制脚本&>将屏幕标准正确错误输出输出至本地目录的esstart.log命名的启动日志文件内，同时使用tail -f 观察es服务启动情况即可

下面附上一些基础的es查询语句：
命令行get方式查询，pengge为示例索引名称

> curl 192.168.108.8:9200/_cat/indices
> curl 192.168.108.8:9200/_cat/health
> curl 192.168.108.8:9200/_cat/nodes
> curl 192.168.108.8:9200/_cat/shards
> curl 192.168.108.8:9200/_cat/allocation
> curl 192.168.108.8:9200/pengge/_count
> curl 192.168.108.8:9200/pengge/_search
> kibana页面方式查询：
> GET _cat/indices
> GET _cat/health
> GET _cat/nodes
> GET _cat/shards
> GET _cat/allocation
> GET /pengge/_count
> GET /pengge/_search

    删除索引
    DELETE pengge*
    删除索引内的指定字段，一定注意删除字段是这个动作参数哦：_update_by_query
    删除字段：@timestamp
    POST /pengge/_update_by_query
    {
     "script": {
     "inline": "ctx._source.remove('@timestamp')",
     "lang": "painless"
     },
     "query": {
     "bool": {
     "must": [
     {
     "exists": {
     "field": "@timestamp"
     }
     }
     ]
     }
     }
    }

***至此elasticsearch服务就简简单单的启动成功啦 ***

至于kibana、logstash一样的道理简单解压./启动即可啦
不在废话叙述啦
简单配置个es 9200读取的节点就可以了如下：

    [root@zabbix config]# egrep -v "#|^$" kibana.yml
    server.port: 5601
    server.host: "192.168.108.143"
    elasticsearch.hosts: ["http://192.168.108.9:9200"]
    
    ./kibana &> start.log & && tail -f start.log

logstash的话主要就是为了针对log日志文件或者txt csv等源数据文件进行整理汇总切割推送给es从而在kibana展示，细节东西下篇文章进行讲解，本期内容就简简单单写写部署启动完事啦
logstash配置的job conf文件可以使用-t参数简单配置的字段语法是否正确如下：

    [root@zabbix bin]# ./logstash -f job/csv-es-debug.conf -t
    Sending Logstash logs to /data/kinbana/logstash7.8.1/logstash-7.8.1/logs which is now configured via log4j2.properties
    [2021-03-09T15:24:03,282][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
    [2021-03-09T15:24:05,485][INFO ][org.reflections.Reflections] Reflections took 46 ms to scan 1 urls, producing 21 keys and 41 values
    Configuration OK
    [2021-03-09T15:24:06,291][INFO ][logstash.runner ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash

***完事就可以-f指定 & 放入后台进行运行使用可爱的logstash啦~***

---

[1]:原文链接：https://blog.csdn.net/pengge2/article/details/114533789